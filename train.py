#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºYOLO11+ByteTrackçš„è¡Œäººæ£€æµ‹ä¸è·Ÿè¸ªç³»ç»Ÿ - è®­ç»ƒè„šæœ¬
è®ºæ–‡: åŸºäºYOLO11+ByteTrackçš„è¡Œäººæ£€æµ‹ä¸è·Ÿè¸ªç³»ç»Ÿè®¾è®¡ä¸å®ç°

æœ¬è„šæœ¬ä½¿ç”¨æœ¬åœ°ultralyticsæºä»£ç ï¼Œæ”¯æŒCBAMæ³¨æ„åŠ›æœºåˆ¶é›†æˆ
é€‚ç”¨äºå­¦æœ¯ç ”ç©¶å’Œç®—æ³•æ”¹è¿›
"""

import os
import sys
import yaml
import torch

# ç¡®ä¿ä½¿ç”¨æœ¬åœ°ultralyticsæºä»£ç ï¼ˆç”¨äºç ”ç©¶å’Œæ”¹è¿›ï¼‰
current_dir = os.getcwd()
local_ultralytics = os.path.join(current_dir, 'ultralytics')

# å°†æœ¬åœ°ultralyticsæ·»åŠ åˆ°Pythonè·¯å¾„çš„æœ€å‰é¢
if local_ultralytics not in sys.path:
    sys.path.insert(0, local_ultralytics)

print(f"ğŸ“š ä½¿ç”¨æœ¬åœ°ultralyticsæºä»£ç : {local_ultralytics}")

try:
    from ultralytics import YOLO
    print("âœ… æˆåŠŸå¯¼å…¥æœ¬åœ°ultralyticsåŒ…")
    
    # éªŒè¯æ˜¯å¦ä½¿ç”¨äº†æœ¬åœ°ç‰ˆæœ¬
    import ultralytics
    ultralytics_path = ultralytics.__file__
    if local_ultralytics in ultralytics_path:
        print(f"âœ… ç¡®è®¤ä½¿ç”¨æœ¬åœ°ultralytics: {ultralytics_path}")
    else:
        print(f"âš ï¸ è­¦å‘Š: å¯èƒ½ä½¿ç”¨äº†ç³»ç»Ÿultralytics: {ultralytics_path}")
        
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥ultralytics: {e}")
    print("è¯·ç¡®ä¿æœ¬åœ°ultralyticsæºä»£ç å®Œæ•´")
    raise

# CBAM utils - ä½¿ç”¨æœ¬åœ°å®ç°
from src.utils.cbam import CBAMWrapper, CBAM
# optional losses (we will use Focal via hyperparams)
from src.utils.losses import FocalLoss, siou_loss

# ============= ç ”ç©¶é…ç½® =============
DATA_YAML = "./dataset/dataset.yaml"  # è¡Œäººæ£€æµ‹æ•°æ®é›†é…ç½®
MODEL_PATH = "./models/YOLO11m.pt"  # é¢„è®­ç»ƒæ¨¡å‹
CBAM_MODEL_YAML = "./models/yolo11m_cbam.yaml"  # CBAMå¢å¼ºé…ç½®
SAVE_DIR = "result/research_weights"  # ç ”ç©¶ç»“æœä¿å­˜ç›®å½•
CBAM_INSERT_LAYERS = [5, 8]  # CBAMæ’å…¥ä½ç½®ï¼ˆåŸºäºç½‘ç»œåˆ†æç¡®å®šï¼‰

# ç ”ç©¶æ¨¡å¼é€‰æ‹©
USE_CONFIG_FILE = True  # True: é…ç½®æ–‡ä»¶æ–¹å¼, False: åŠ¨æ€æ’å…¥æ–¹å¼
RESEARCH_MODE = "cbam_integration"  # ç ”ç©¶æ¨¡å¼æ ‡è¯†

# å®éªŒé…ç½®
EXPERIMENT_NAME = "YOLO11m_CBAM_Pedestrian"
PAPER_VERSION = "v1.0"
# =================================

os.makedirs(SAVE_DIR, exist_ok=True)

def log_research_info():
    """è®°å½•ç ”ç©¶ä¿¡æ¯ç”¨äºè®ºæ–‡"""
    info = {
        "paper_title": "åŸºäºYOLO11+ByteTrackçš„è¡Œäººæ£€æµ‹ä¸è·Ÿè¸ªç³»ç»Ÿè®¾è®¡ä¸å®ç°",
        "experiment_name": EXPERIMENT_NAME,
        "version": PAPER_VERSION,
        "model_base": "YOLO11m",
        "enhancement": "CBAM Attention Mechanism",
        "dataset": "Pedestrian Detection Dataset",
        "research_mode": RESEARCH_MODE,
        "cbam_layers": CBAM_INSERT_LAYERS,
        "ultralytics_source": "Local (Modified for Research)"
    }
    
    info_path = os.path.join(SAVE_DIR, "research_info.yaml")
    with open(info_path, "w", encoding='utf-8') as f:
        yaml.dump(info, f, allow_unicode=True)
    
    print("ğŸ“‹ ç ”ç©¶ä¿¡æ¯å·²è®°å½•:", info_path)
    return info

def insert_cbam_into_model(yolo_model, insert_layers=CBAM_INSERT_LAYERS):
    """
    ç ”ç©¶ç‰ˆCBAMæ’å…¥å‡½æ•° - ç”¨äºç®—æ³•æ”¹è¿›ç ”ç©¶
    """
    print(f"ğŸ”¬ å¼€å§‹CBAMé›†æˆç ”ç©¶ - æ’å…¥ä½ç½®: {insert_layers}")
    
    m = yolo_model.model  # DetectionModel
    if not hasattr(m, "model"):
        print("âš  æ¨¡å‹ç»“æ„å¼‚å¸¸ï¼Œæ— æ³•è¿›è¡ŒCBAMé›†æˆç ”ç©¶")
        return False

    seq = m.model
    print(f"ğŸ“Š æ¨¡å‹åˆ†æ: å…±{len(seq)}ä¸ªå­æ¨¡å—")

    # ç ”ç©¶ç”¨çš„è¯¦ç»†å‰å‘ä¼ æ’­åˆ†æ
    device = next(yolo_model.parameters()).device
    yolo_model.eval()

    with torch.no_grad():
        # ä½¿ç”¨æ ‡å‡†è¾“å…¥å°ºå¯¸è¿›è¡Œç½‘ç»œåˆ†æ
        dummy_input = torch.zeros((1, 3, 640, 640)).to(device)
        layer_outputs = []
        x = dummy_input

        print("ğŸ” ç½‘ç»œå±‚åˆ†æï¼ˆç”¨äºè®ºæ–‡æŠ€æœ¯ç»†èŠ‚ï¼‰:")
        for i, layer in enumerate(seq):
            try:
                if hasattr(layer, 'f') and layer.f != -1:
                    if isinstance(layer.f, int):
                        x = layer_outputs[layer.f] if layer.f >= 0 else x
                    else:
                        x = [x if j == -1 else layer_outputs[j] for j in layer.f]

                x = layer(x)
                layer_outputs.append(x)

                # è¯¦ç»†çš„å±‚åˆ†æä¿¡æ¯ï¼ˆç”¨äºè®ºæ–‡ï¼‰
                if isinstance(x, torch.Tensor):
                    channels = x.shape[1]
                    spatial_size = f"{x.shape[2]}x{x.shape[3]}"
                    print(f"  å±‚{i:2d}: {layer.__class__.__name__:15s} | é€šé“: {channels:3d} | ç©ºé—´: {spatial_size:8s}")
                elif isinstance(x, (list, tuple)) and len(x) > 0 and isinstance(x[0], torch.Tensor):
                    channels = x[0].shape[1]
                    spatial_size = f"{x[0].shape[2]}x{x[0].shape[3]}"
                    print(f"  å±‚{i:2d}: {layer.__class__.__name__:15s} | é€šé“: {channels:3d} | ç©ºé—´: {spatial_size:8s} (å¤šè¾“å‡º)")

            except Exception as e:
                print(f"  å±‚{i:2d}: {layer.__class__.__name__:15s} | åˆ†æå¤±è´¥: {e}")
                layer_outputs.append(None)

    # CBAMé›†æˆå®éªŒ
    print(f"\nğŸ§ª CBAMæ³¨æ„åŠ›æœºåˆ¶é›†æˆå®éªŒ:")
    inserted = 0
    cbam_info = []
    
    for idx in insert_layers:
        if idx < 0 or idx >= len(seq):
            print(f"âŒ ç´¢å¼•{idx}è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡")
            continue

        if idx >= len(layer_outputs) or layer_outputs[idx] is None:
            print(f"âŒ ç´¢å¼•{idx}æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡")
            continue

        try:
            target = seq[idx]
            output = layer_outputs[idx]

            # è·å–é€šé“æ•°
            if isinstance(output, torch.Tensor):
                out_ch = output.shape[1]
                spatial_size = f"{output.shape[2]}x{output.shape[3]}"
            elif isinstance(output, (list, tuple)) and len(output) > 0:
                out_ch = output[0].shape[1]
                spatial_size = f"{output[0].shape[2]}x{output[0].shape[3]}"
            else:
                print(f"âŒ ç´¢å¼•{idx}è¾“å‡ºæ ¼å¼ä¸æ”¯æŒ")
                continue

            # åˆ›å»ºCBAMæ¨¡å—ï¼ˆç ”ç©¶ç‰ˆï¼‰
            cbam = CBAM(out_ch, ratio=16, kernel_size=7)  # æ ‡å‡†CBAMé…ç½®
            wrapper = CBAMWrapper(target, cbam)
            seq[idx] = wrapper
            
            # è®°å½•CBAMé›†æˆä¿¡æ¯ï¼ˆç”¨äºè®ºæ–‡ï¼‰
            cbam_info.append({
                "layer_index": idx,
                "layer_type": target.__class__.__name__,
                "channels": out_ch,
                "spatial_size": spatial_size,
                "cbam_params": {
                    "ratio": 16,
                    "kernel_size": 7
                }
            })
            
            inserted += 1
            print(f"âœ… å±‚{idx}: {target.__class__.__name__} + CBAM | é€šé“:{out_ch} | ç©ºé—´:{spatial_size}")

        except Exception as e:
            print(f"âŒ å±‚{idx}CBAMé›†æˆå¤±è´¥: {e}")

    # ä¿å­˜CBAMé›†æˆä¿¡æ¯ï¼ˆç”¨äºè®ºæ–‡åˆ†æï¼‰
    if cbam_info:
        cbam_info_path = os.path.join(SAVE_DIR, "cbam_integration_analysis.yaml")
        with open(cbam_info_path, "w", encoding='utf-8') as f:
            yaml.dump(cbam_info, f, allow_unicode=True)
        print(f"ğŸ“Š CBAMé›†æˆåˆ†æå·²ä¿å­˜: {cbam_info_path}")

    yolo_model.train()
    print(f"ğŸ¯ CBAMé›†æˆå®Œæˆ: {inserted}/{len(insert_layers)}ä¸ªä½ç½®æˆåŠŸ")
    return inserted > 0

if __name__ == "__main__":
    print("ğŸ“ åŸºäºYOLO11+ByteTrackçš„è¡Œäººæ£€æµ‹ä¸è·Ÿè¸ªç³»ç»Ÿ - ç ”ç©¶è®­ç»ƒ")
    print("=" * 60)
    
    # è®°å½•ç ”ç©¶ä¿¡æ¯
    research_info = log_research_info()
    
    if USE_CONFIG_FILE:
        print("ğŸ“‹ ä½¿ç”¨é…ç½®æ–‡ä»¶æ–¹å¼ (é€‚åˆè®ºæ–‡å®éªŒ)")
        print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {CBAM_MODEL_YAML}")
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(CBAM_MODEL_YAML):
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CBAM_MODEL_YAML}")
            print("ğŸ’¡ è¯·ç¡®ä¿å·²åˆ›å»ºCBAMé…ç½®æ–‡ä»¶")
            sys.exit(1)
            
        model = YOLO(CBAM_MODEL_YAML)
        print("âœ… æˆåŠŸåŠ è½½CBAMå¢å¼ºæ¨¡å‹")
        
    else:
        print("ğŸ”§ ä½¿ç”¨åŠ¨æ€æ’å…¥æ–¹å¼ (é€‚åˆç®—æ³•ç ”ç©¶)")
        model = YOLO(MODEL_PATH)
        print("âœ… æˆåŠŸåŠ è½½åŸºç¡€YOLO11mæ¨¡å‹")
        
        # è¿›è¡ŒCBAMé›†æˆç ”ç©¶
        cbam_success = insert_cbam_into_model(model, CBAM_INSERT_LAYERS)
        if cbam_success:
            print("ğŸ‰ CBAMé›†æˆç ”ç©¶æˆåŠŸ")
        else:
            print("âš ï¸ CBAMé›†æˆæœªå®Œå…¨æˆåŠŸï¼Œç»§ç»­ä½¿ç”¨åŸºç¡€æ¨¡å‹")

    # === ç ”ç©¶ç”¨è¶…å‚æ•°é…ç½® ===
    research_hyp = {
        # å­¦ä¹ ç‡ç­–ç•¥ï¼ˆé€‚åˆè¡Œäººæ£€æµ‹ï¼‰
        "lr0": 0.01,        # åˆå§‹å­¦ä¹ ç‡
        "lrf": 0.01,        # æœ€ç»ˆå­¦ä¹ ç‡æ¯”ä¾‹
        "momentum": 0.937,   # SGDåŠ¨é‡
        "weight_decay": 0.0005,  # æƒé‡è¡°å‡
        
        # æŸå¤±å‡½æ•°æƒé‡ï¼ˆé’ˆå¯¹è¡Œäººæ£€æµ‹ä¼˜åŒ–ï¼‰
        "box": 7.5,         # è¾¹ç•Œæ¡†æŸå¤±æƒé‡
        "cls": 0.5,         # åˆ†ç±»æŸå¤±æƒé‡
        "dfl": 1.5,         # DFLæŸå¤±æƒé‡
        "fl_gamma": 1.5,    # Focal Loss gammaå‚æ•°
        
        # æ•°æ®å¢å¼ºç­–ç•¥ï¼ˆè¡Œäººæ£€æµ‹ä¸“ç”¨ï¼‰
        "mosaic": 1.0,      # Mosaicå¢å¼ºæ¦‚ç‡
        "mixup": 0.15,      # MixUpå¢å¼ºæ¦‚ç‡
        "copy_paste": 0.3,  # Copy-Pasteå¢å¼ºæ¦‚ç‡
        
        # é¢œè‰²å¢å¼º
        "hsv_h": 0.015,     # è‰²è°ƒå¢å¼º
        "hsv_s": 0.7,       # é¥±å’Œåº¦å¢å¼º
        "hsv_v": 0.4,       # æ˜åº¦å¢å¼º
        
        # å‡ ä½•å˜æ¢
        "degrees": 5.0,     # æ—‹è½¬è§’åº¦
        "translate": 0.1,   # å¹³ç§»æ¯”ä¾‹
        "scale": 0.5,       # ç¼©æ”¾æ¯”ä¾‹
        "shear": 0.0,       # å‰ªåˆ‡å˜æ¢
        "perspective": 0.0, # é€è§†å˜æ¢
        "flipud": 0.0,      # ä¸Šä¸‹ç¿»è½¬
        "fliplr": 0.5,      # å·¦å³ç¿»è½¬
    }

    # ä¿å­˜ç ”ç©¶ç”¨è¶…å‚æ•°
    hyp_path = os.path.join(SAVE_DIR, f"{EXPERIMENT_NAME}_hyperparameters.yaml")
    with open(hyp_path, "w", encoding='utf-8') as f:
        yaml.dump(research_hyp, f, allow_unicode=True)
    print(f"ğŸ“‹ ç ”ç©¶è¶…å‚æ•°å·²ä¿å­˜: {hyp_path}")

    # === å¼€å§‹ç ”ç©¶è®­ç»ƒ ===
    print("\nğŸš€ å¼€å§‹ç ”ç©¶è®­ç»ƒ - åŸºäºYOLO11+CBAMçš„è¡Œäººæ£€æµ‹")
    print("=" * 60)

    try:
        # è®­ç»ƒé…ç½®ï¼ˆé€‚åˆå­¦æœ¯ç ”ç©¶ï¼‰
        training_results = model.train(
            data=DATA_YAML,
            epochs=200,          # å……åˆ†è®­ç»ƒç”¨äºè®ºæ–‡å®éªŒ
            imgsz=640,           # æ ‡å‡†è¾“å…¥å°ºå¯¸
            batch=16,            # æ ¹æ®GPUè°ƒæ•´
            project=SAVE_DIR,
            name=EXPERIMENT_NAME,
            workers=8,
            optimizer="AdamW",   # ç°ä»£ä¼˜åŒ–å™¨
            
            # ç›´æ¥ä¼ å…¥è¶…å‚æ•°
            lr0=research_hyp["lr0"],
            lrf=research_hyp["lrf"],
            momentum=research_hyp["momentum"],
            weight_decay=research_hyp["weight_decay"],
            box=research_hyp["box"],
            cls=research_hyp["cls"],
            dfl=research_hyp["dfl"],
            fl_gamma=research_hyp["fl_gamma"],
            
            # æ•°æ®å¢å¼º
            mosaic=research_hyp["mosaic"],
            mixup=research_hyp["mixup"],
            copy_paste=research_hyp["copy_paste"],
            hsv_h=research_hyp["hsv_h"],
            hsv_s=research_hyp["hsv_s"],
            hsv_v=research_hyp["hsv_v"],
            degrees=research_hyp["degrees"],
            translate=research_hyp["translate"],
            scale=research_hyp["scale"],
            shear=research_hyp["shear"],
            perspective=research_hyp["perspective"],
            flipud=research_hyp["flipud"],
            fliplr=research_hyp["fliplr"],
            
            # ç ”ç©¶é…ç½®
            save=True,           # ä¿å­˜æ£€æŸ¥ç‚¹
            save_period=10,      # æ¯10è½®ä¿å­˜ä¸€æ¬¡
            cache=False,         # ä¸ç¼“å­˜æ•°æ®é›†
            device=0,            # GPUè®¾å¤‡
            pretrained=True,     # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
            verbose=True,        # è¯¦ç»†è¾“å‡º
            
            # éªŒè¯é…ç½®
            val=True,            # å¯ç”¨éªŒè¯
            plots=True,          # ç”Ÿæˆè®­ç»ƒå›¾è¡¨
            
            # æ—©åœé…ç½®
            patience=50,         # æ—©åœè€å¿ƒå€¼
        )

        print("\nğŸ‰ ç ”ç©¶è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“Š è®­ç»ƒç»“æœä¿å­˜åœ¨: {SAVE_DIR}")
        print(f"ğŸ“ˆ å¯ç”¨äºè®ºæ–‡çš„è®­ç»ƒå›¾è¡¨å’Œæ—¥å¿—å·²ç”Ÿæˆ")
        
        # ä¿å­˜è®­ç»ƒæ€»ç»“ï¼ˆç”¨äºè®ºæ–‡ï¼‰
        training_summary = {
            "experiment_info": research_info,
            "training_config": research_hyp,
            "results_path": SAVE_DIR,
            "model_type": "YOLO11m + CBAM" if (USE_CONFIG_FILE or cbam_success) else "YOLO11m",
            "dataset": "Pedestrian Detection",
            "training_epochs": 200,
            "final_metrics": "è§è®­ç»ƒæ—¥å¿—æ–‡ä»¶"
        }
        
        summary_path = os.path.join(SAVE_DIR, "training_summary_for_paper.yaml")
        with open(summary_path, "w", encoding='utf-8') as f:
            yaml.dump(training_summary, f, allow_unicode=True)
        print(f"ğŸ“‹ è®ºæ–‡ç”¨è®­ç»ƒæ€»ç»“å·²ä¿å­˜: {summary_path}")

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("ğŸ’¡ å»ºè®®æ£€æŸ¥:")
        print("   - æ•°æ®é›†è·¯å¾„å’Œæ ¼å¼")
        print("   - GPUå†…å­˜æ˜¯å¦è¶³å¤Ÿ")
        print("   - è°ƒæ•´batch size")
        print("   - æ£€æŸ¥CBAMé›†æˆæ˜¯å¦æ­£ç¡®")

    print("\nğŸ“š è®ºæ–‡ç›¸å…³æ–‡ä»¶:")
    print(f"   - ç ”ç©¶ä¿¡æ¯: {os.path.join(SAVE_DIR, 'research_info.yaml')}")
    print(f"   - è¶…å‚æ•°é…ç½®: {hyp_path}")
    print(f"   - CBAMåˆ†æ: {os.path.join(SAVE_DIR, 'cbam_integration_analysis.yaml')}")
    print(f"   - è®­ç»ƒæ€»ç»“: {os.path.join(SAVE_DIR, 'training_summary_for_paper.yaml')}")
    print(f"   - è®­ç»ƒæ—¥å¿—å’Œå›¾è¡¨: {SAVE_DIR}/{EXPERIMENT_NAME}/")